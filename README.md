# ğŸš€ AI/LLM Libraries by Category ğŸ“š

Welcome to an exciting exploration of cutting-edge libraries and tools in the AI and Large Language Models (LLMs) ecosystem! ğŸŒŸ

Weâ€™ve organized these powerful tools by their primary use-case, focusing especially on open-source Python-based projects, with notable proprietary services also included. Each tool listed provides a quick description, a link to its repo or official page, and its GitHub stars ğŸŒŸ for quick reference.

---

## 1ï¸âƒ£ Fine-Tuning ğŸ› ï¸
- **ğŸ¤— Hugging Face Transformers** ([GitHub â˜…141k](https://github.com/huggingface/transformers)): Easily fine-tune thousands of pretrained models across PyTorch, TensorFlow, and JAX.
- **ğŸš€ PEFT (HF)** ([GitHub â˜…17.8k](https://github.com/huggingface/peft)): Efficient parameter-tuning with LoRA, adapters, and more for quick LLM adaptations.
- **ğŸ§  trlX (CarperAI)** ([GitHub â˜…4.6k](https://github.com/CarperAI/trlx)): Reinforcement Learning from Human Feedback (RLHF) for fine-tuning LLMs.
- **ğŸ¦ Axolotl** ([GitHub â˜…8.9k](https://github.com/OpenAccess-AI-Collective/axolotl)): Simplified fine-tuning via YAML for LLMs, LoRA/QLoRA, and instruction tuning.
- **ğŸ’§ H2O LLM Studio** ([GitHub â˜…4.2k](https://github.com/h2oai/h2o-llmstudio)): No-code GUI for LLM fine-tuning with experiment tracking.
- **ğŸŒˆ LLamaFactory** ([GitHub â˜…44.4k](https://github.com/hiyouga/LLaMA-Factory)): YAML and UI based easy fine-tuning.
- **ğŸ”¬ MS-Swift** ([GitHub â˜…44.4k](https://github.com/modelscope/ms-swift)):LLM fine-tuning.
- **ğŸ§  TorchTune** ([GitHub â˜…44.4k](https://github.com/pytorch/torchtune)):LLM fine-tuning for Pytorch team.

## 2ï¸âƒ£ Retrieval-Augmented Generation (RAG) ğŸ”
- **ğŸ¦™ LlamaIndex** ([GitHub â˜…40k](https://github.com/jerryjliu/llama_index)): Connect custom data to LLM applications.
- **ğŸŒ¾ Haystack** ([GitHub â˜…19.8k](https://github.com/deepset-ai/haystack)): End-to-end RAG pipelines for scalable QA and document search.
- **ğŸŒˆ Chroma** ([GitHub â˜…18.6k](https://github.com/chroma-core/chroma)): Easy-to-use local vector database for embeddings.
- **ğŸ”¬ Faiss (Facebook AI)** ([GitHub â˜…33.7k](https://github.com/facebookresearch/faiss)): Efficient large-scale vector indexing and similarity search.
- **ğŸ‰ Milvus** ([GitHub â˜…33.2k](https://github.com/milvus-io/milvus)): Scalable cloud-native vector database for embedding retrieval.
- **ğŸŒ² Pinecone** ([Website](https://pinecone.io)): Fully-managed proprietary vector database service for large-scale semantic search.

## 3ï¸âƒ£ Data-Related Tools ğŸ“‚
- **ğŸ¤— Hugging Face Datasets** ([GitHub â˜…19.8k](https://github.com/huggingface/datasets)): Quick access to thousands of ML datasets.
- **ğŸ“¦ DVC (Data Version Control)** ([GitHub â˜…14.3k](https://github.com/iterative/dvc)): Version control for datasets and reproducible ML workflows.
- **ğŸ§¹ Cleanlab** ([GitHub â˜…10.2k](https://github.com/cleanlab/cleanlab)): Automatically detect and fix dataset issues.
- **ğŸ¨ Argilla** ([GitHub â˜…4.4k](https://github.com/argilla-io/argilla)): Collaborative dataset labeling and management platform.
- **ğŸ¬ Snorkel** ([GitHub â˜…5.8k](https://github.com/snorkel-team/snorkel)): Programmatic labeling and weak supervision for datasets.

## 4ï¸âƒ£ Pre-Training Frameworks ğŸŒ
- **ğŸ‹ï¸ Colossal-AI** ([GitHub â˜…40.6k](https://github.com/hpcaitech/ColossalAI)): Efficient distributed training for massive AI models.
- **ğŸš„ DeepSpeed (Microsoft)** ([GitHub â˜…37.4k](https://github.com/microsoft/DeepSpeed)): Memory optimizations and scaling for huge models.
- **ğŸ“– Fairseq (Meta)** ([GitHub â˜…31.2k](https://github.com/facebookresearch/fairseq)): Powerful toolkit for sequence-to-sequence model training.
- **âš¡ Megatron-LM (NVIDIA)** ([GitHub â˜…11.8k](https://github.com/NVIDIA/Megatron-LM)): Efficient multi-node transformer training at GPT-scale.
- **ğŸ¼ MosaicML Composer** ([GitHub â˜…5.3k](https://github.com/mosaicml/composer)): Optimized training with built-in enhancements for large-scale models.

## 5ï¸âƒ£ AI Agents ğŸ¤–
- **ğŸ”— LangChain** ([GitHub â˜…103k](https://github.com/langchain-ai/langchain)): Chain LLM calls and tools to build powerful agent-based apps.
- **ğŸ¤– Auto-GPT** ([GitHub â˜…21.2k](https://github.com/Significant-Gravitas/Auto-GPT)): Autonomous GPT agents that achieve user-defined goals.
- **ğŸ›  Semantic Kernel (Microsoft)** ([GitHub](https://github.com/microsoft/semantic-kernel)): Developer-friendly plugin system to orchestrate AI tasks.
- **ğŸ¦¸ LangChain** ([GitHub â˜…103k](https://github.com/langchain-ai/langchain)): Orchestrate tools and LLM reasoning.

## 5ï¸âƒ£ LLM Serving ğŸš„
- **ğŸš€ vLLM** ([GitHub â˜…24.2k](https://github.com/vllm-project/vllm)): High-throughput and memory-efficient inference serving for LLMs.
- **ğŸ¯ Hugging Face TGI** ([GitHub â˜…9.9k](https://github.com/huggingface/text-generation-inference)): Optimized server-side inference for HF models.
- **ğŸŒŸ OpenLLM** ([GitHub â˜…11k](https://github.com/bentoml/OpenLLM)): Versatile LLM serving with multi-GPU parallelism and easy deployments.
- **ğŸ”§ FasterTransformer (NVIDIA)** ([GitHub â˜…6.5k](https://github.com/NVIDIA/FasterTransformer)): Optimized transformer kernels for maximum GPU performance.
- **ğŸŒ©ï¸ OpenAI API** ([Website](https://openai.com/api)): Official OpenAI-hosted proprietary model inference.

## 6ï¸âƒ£ GPU Low-Level Libraries âš™ï¸
- **ğŸ› ï¸ NVIDIA Cutlass** ([GitHub](https://github.com/NVIDIA/cutlass)): Optimized CUDA kernels for deep learning.
- **ğŸ”± Triton (OpenAI)** ([GitHub](https://github.com/openai/triton)): Python-based JIT compiler for efficient GPU programming.
- **ğŸ”¥ xFormers (Meta)** ([GitHub](https://github.com/facebookresearch/xformers)): Modular and efficient transformer components.
- **âš¡ FlashAttention** ([GitHub](https://github.com/Dao-AILab/flash-attention)): Ultra-fast attention mechanisms optimized for GPUs.

## 6ï¸âƒ£ Evaluation ğŸ…
- **ğŸ“ˆ HELM (Stanford)** ([GitHub](https://github.com/stanford-crfm/helm)): Benchmark models on accuracy, robustness, and more.
- **ğŸ”¬ EleutherAI LM Evaluation Harness** ([GitHub](https://github.com/EleutherAI/lm-evaluation-harness)): Comprehensive evaluation across diverse tasks.
- **ğŸ›  BIG-bench** ([GitHub](https://github.com/google/BIG-bench)): Community-driven diverse benchmark for comprehensive LLM evaluation.

---
âœ¨ **Contribute, star â­, and explore these cutting-edge tools to enhance your AI workflows!**

